# api/services/llm_openai.py
from __future__ import annotations
import os, json
from openai import OpenAI
from views import _int_or_none

client = OpenAI()  # OPENAI_API_KEYë¥¼ .envì—ì„œ ì½ìŒ
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

SYSTEM_KO = (
    "ë„ˆëŠ” ì…ì§€ ì¶”ì²œ ì‚¬ìœ ë¥¼ ì‘ì„±í•˜ëŠ” ë„ìš°ë¯¸ë‹¤. "
    "ìœ ë™ì¸êµ¬ëŠ” 'ë³´í–‰ëŸ‰'ì´ë©° ì‹¤ì œ ë°©ë¬¸ìê°€ ì•„ë‹˜ì„ ëª…ì‹œí•˜ë¼. "
    "featuresì— 'assumed_visit_rate'ì™€ 'estimated_visitors'ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ì‚¬ìš©í•´, "
    "ì „í™˜ìœ¨ r% ê°€ì • ì‹œ ë°©ë¬¸ì ì¶”ì • Nëª…ì„ ì‚¬ì‹¤ëŒ€ë¡œ ì„¤ëª…í•˜ë¼. "
    "ê³¼ì¥/ì¶”ì •ì¹˜ ì„ì˜ ìƒì„± ê¸ˆì§€, ì£¼ì–´ì§„ ê°’ë§Œ ì‚¬ìš©."
)

def _fallback(f: dict) -> str:
    parts = []
    if f.get("distance_km") is not None:
        parts.append(f"ìœ„ì¹˜ {f['distance_km']:.1f}km")
    if f.get("monthly_rent") is not None:
        parts.append(f"ì„ëŒ€ë£Œ {f['monthly_rent']:,}ì›")
    if f.get("deposit") is not None:
        parts.append(f"ë³´ì¦ê¸ˆ {f['deposit']:,}ì›")
    if f.get("daily_footfall_avg") is not None:
        parts.append(f"ì¼ ìœ ë™ì¸êµ¬ {f['daily_footfall_avg']:,}ëª…")

    vr = f.get("assumed_visit_rate")
    ev = _int_or_none(f.get("estimated_visitors"))
    if vr is not None and ev is not None:
        parts.append(f"(ìœ ë™ì¸êµ¬ëŠ” ë³´í–‰ëŸ‰ì´ë©°, ì „í™˜ìœ¨ {vr*100:.1f}% ê°€ì • ì‹œ ë°©ë¬¸ì {ev:,}ëª… ì¶”ì •)")

    base = ", ".join(parts) if parts else "ì—¬ëŸ¬ ì§€í‘œê°€ ê· í˜•ì "
    return base + " ë“±ì„ ì¢…í•©í•´ ìƒìœ„ í›„ë³´ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤."

def explain(features: dict, lang: str = "ko") -> str:
    try:
        prompt = f"""
ë‹¤ìŒ JSON ì§€í‘œë§Œ ê·¼ê±°ë¡œ ì•„ë˜ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ì‘ì„±í•˜ë¼.
ê·œì¹™:
- ê° í•­ëª©ì€ ì •í™•íˆ 2ë¬¸ì¥
- ê³¼ì¥ ë° ì„ì˜ ì¶”ì •/ê³„ì‚°(ì˜ˆ: ë§¤ì¶œ, ìˆœì´ìµ) ê¸ˆì§€. ì£¼ì–´ì§„ ìˆ˜ì¹˜ë§Œ ì–¸ê¸‰
- ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 'ë°ì´í„° ì—†ìŒ'ì´ë¼ê³  ì ê¸°
- ì „ì²´ëŠ” 900ì ì´ë‚´

í˜•ì‹:
1. ì¶”ì²œ ì‚¬ìœ 
2. ì˜ˆìƒ ë§¤ì¶œ ìˆ˜ìµ ì‚¬ìœ 
3. ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€   
4. ì°½ì—… ìš´ì˜ íŒ
5. ì •ë¶€ ì§€ì›ê¸ˆ ì •ë³´

JSON:
{json.dumps(features, ensure_ascii=False)}
""".strip()

        resp = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_KO},
                {"role": "user",   "content": prompt},
            ],
            temperature=0.2,
            max_tokens=300,   # ğŸ”¼ ì¶©ë¶„íˆ ëŠ˜ë¦¼
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception:
        return _fallback(features)
